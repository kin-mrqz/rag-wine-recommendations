{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c0fc4-01ea-41de-9dc3-2fc9d755e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install bs4 sentence-transformers tqdm langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94658a9f-9156-4432-bbf7-5547e9a1c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader, GoogleDriveLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI  # Uses OpenAI-compatible API\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb40f71-d897-4055-a8eb-d3e23824dbfc",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb38446-6146-41f6-84d4-7798de8345d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pdf contents\n",
    "def load_pdf(path: str):\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()\n",
    "\n",
    "# loading website contents\n",
    "def load_web(path: str):\n",
    "    loader = WebBaseLoader(\n",
    "        web_path = (path,),\n",
    "        bs_kwargs = dict(\n",
    "          parse_only = bs4.SoupStrainer(\n",
    "              class_ = (\"post-content\", \"post-title\", \"post-header\") # depending on CSS class\n",
    "          )  \n",
    "        ),\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "# loading google doc contents (see below)\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def extract_json_from_llm_output(output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts and parses a JSON object from LLM output that may include Markdown formatting.\n",
    "    Handles triple backticks, optional language labels, and excessive whitespace.\n",
    "    \"\"\"\n",
    "    output = output.strip()\n",
    "\n",
    "    # Match content between ```json ... ``` or just ``` ... ```\n",
    "    match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", output, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "    else:\n",
    "        json_str = output\n",
    "\n",
    "    return json.loads(json_str)\n",
    "\n",
    "def get_doc_id(url):\n",
    "    return url.split(\"/\")[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecbdfe-e90d-4107-b067-5d0b1c906c38",
   "metadata": {},
   "source": [
    "OpenAI embeddings don't work in HK (even with VPN). Hence, HuggingFace embedding model was used. Also feel free to test out API calls from DeepSeep or replace it with your choice of LLM for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9351f27e-9f8a-4ee3-ba55-f1689883be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.deepseek.com/v1\",\n",
    "    openai_api_key=\"sk-ea1868b36aa34a36be9a223e75c1c63c\", \n",
    "    model=\"deepseek-chat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b52757-b688-41af-ae35-fbfa1f376195",
   "metadata": {},
   "source": [
    "**Intermediate Step: Preparing Google Cloud API**\n",
    "- for loading contents of Google Docs\n",
    "- you can also try loading content using **load_pdf()** and **load_web**\n",
    "- the code below uses my Google Cloud credentials included in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249a1e4-5085-430d-97bd-b00cd1fc87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade google-auth google-auth-oauthlib google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009ded1-d845-4a7c-b0b1-d0e360bc2ddd",
   "metadata": {},
   "source": [
    "doc_links contains the Google Docs from the Sommelier Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cca6db-25f5-4bb6-aae9-d6a47f4fd567",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_links = [\n",
    "    \"https://docs.google.com/document/d/1MvX9CTrVcoWg7WLAscq2MmnhTIrR0hZIGkpJMqhgflo/edit?tab=t.0\",\n",
    "    \"https://docs.google.com/document/d/1NcV9_JGjMfA4WlihW3vNTduy24NBWdy1RWXrA2W0BIk/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/193rx2Rh6u-Ud40k-rgnqSQs-94SvHdeXPrPxOWK59X0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1vRDsn5o5mdymOEJ_O0tS4wcOjsAjt_2mLZqFfvgDUOs/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1JceLBII727AZzSrDFfdGthJ1G4PhCDsA8sEm_dQMVr0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1yonU4qcysNkgd0BvbFmeIW9NF2ARErRJVW8QZynJyvM/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1bq2AE1Jy6cQFt1xgjqtkof12Lw6F6fujqTlN1nZnh0A/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1i-OcQeo7XOG83gS2ay2u0SLMWs4f8FG0JE_7l87qJkw/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1PyZE8v3S3aUY66lFn97q0vaXDHc60lyso2oUFP0htjY/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1Dudd7-6yl_UQrxfGa3MJZlKOfzHQdqWg0fb8Z9RzBec/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1cjhrhCccuwiIh0ujj8QeamJ2JHhI6CjPmO84t1DSRZ0/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1ESlfU6v8jseFlllZb3eaUeCJt69EIMsZiyMrDac-wX8/edit?usp=sharing\",\n",
    "    \"https://docs.google.com/document/d/1xQhAkC3oP2cb262EjaHCV6CxEgeEGUsKrC8pH2p6RiY/edit?usp=sharing\"\n",
    "    \n",
    "]\n",
    "\n",
    "g_docs = GoogleDriveLoader(\n",
    "    document_ids = [get_doc_id(i) for i in docs_links],\n",
    "    credentials_path = \"credentials_google.json\",\n",
    "    token_path = \"token.json\"\n",
    ").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9dba0-a5b4-44db-8266-0f3e324d0674",
   "metadata": {},
   "source": [
    "Chroma seems to be a convenient alternative, as a chroma vectorstore can be converted directly into a retriever that returns k relevant documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b795521-0dc5-49c4-bc4e-c527627787e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 300, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(g_docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = splits,\n",
    "    embedding = embd\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d77ae9-9457-4958-8bfd-25f627b52ac5",
   "metadata": {},
   "source": [
    "**Preparing Pydantic Schemas and LLM Modelfiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a0ead-e40a-4211-8867-43576be8a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class FoodPairing(BaseModel):\n",
    "    \"\"\"Information about a food item that pairs well with a wine.\"\"\"\n",
    "    \n",
    "    dish_name: Optional[str] = Field(\n",
    "        default=None, description=\"Name of the dish (e.g., 'roast duck', 'brie cheese').\"\n",
    "    )\n",
    "    pairing_type: Optional[str] = Field(\n",
    "        default=None, description=\"Type of pairing (e.g., 'complementary', 'contrast').\"\n",
    "    )\n",
    "    course: Optional[str] = Field(\n",
    "        default=None, description=\"Course type (e.g., 'starter', 'main', 'dessert').\"\n",
    "    )\n",
    "    description: Optional[str] = Field(\n",
    "        default=None, description=\"Description of the pairing experience or rationale.\"\n",
    "    )\n",
    "    suitability: Optional[int] = Field(\n",
    "        default=None, description=\"Suitability score or rating for the pairing (e.g., 1â€“10).\"\n",
    "    )\n",
    "    acidity: Optional[str] = Field(\n",
    "        default=None, description=\"Acidity match or contrast for the dish (e.g., 'low', 'crisp').\"\n",
    "    )\n",
    "    regional_pairing: Optional[str] = Field(\n",
    "        default=None, description=\"Regional or traditional pairing origin (e.g., 'Provence').\"\n",
    "    )\n",
    "    sweetness: Optional[str] = Field(\n",
    "        default=None, description=\"Sweetness level or match (e.g., 'dry', 'sweet').\"\n",
    "    )\n",
    "    \n",
    "\n",
    "class WineMetadata(BaseModel):\n",
    "    \"\"\"Structured metadata filters for querying a wine product database.\"\"\"\n",
    "\n",
    "    wine_name: Optional[str] = Field(\n",
    "        default=None, description=\"Specific wine name mentioned in the query.\"\n",
    "    )\n",
    "    variant_id: Optional[int] = Field(\n",
    "        default=None, description=\"Specific product variant ID.\"\n",
    "    )\n",
    "    size: Optional[str] = Field(\n",
    "        default=None, description=\"Bottle size (e.g., '750ml', '1.5L').\"\n",
    "    )\n",
    "    volume_unit: Optional[str] = Field(\n",
    "        default=None, description=\"Units for volume (e.g., 'ml', 'L').\"\n",
    "    )\n",
    "    rating: Optional[str] = Field(\n",
    "        default=None, description=\"Expert or user rating (e.g., '90+', '4.5 stars').\"\n",
    "    )\n",
    "    stock: Optional[int] = Field(\n",
    "        default=None, description=\"Stock availability if specified.\"\n",
    "    )\n",
    "\n",
    "    min_price: Optional[float] = Field(\n",
    "        default=None, description=\"Minimum price filter (inclusive).\"\n",
    "    )\n",
    "    max_price: Optional[float] = Field(\n",
    "        default=None, description=\"Maximum price filter (inclusive).\"\n",
    "    )\n",
    "\n",
    "    winemaker: Optional[str] = Field(\n",
    "        default=None, description=\"Name of the winemaker or producer.\"\n",
    "    )\n",
    "    vintage: Optional[int] = Field(\n",
    "        default=None, description=\"Vintage year of the wine (e.g., 2015).\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"Country of origin.\"\n",
    "    )\n",
    "    region: Optional[str] = Field(\n",
    "        default=None, description=\"Region or appellation.\"\n",
    "    )\n",
    "    wine_type: Optional[str] = Field(\n",
    "        default=None, description=\"Type of wine (e.g., red, white, rosÃ©, sparkling).\"\n",
    "    )\n",
    "    wine_grapes: Optional[str] = Field(\n",
    "        default=None, description=\"Grape variety or blend (e.g., Merlot, Syrah).\"\n",
    "    )\n",
    "\n",
    "    level_to_drink: Optional[str] = Field(\n",
    "        default=None, description=\"Drinkability status (e.g., 'drink now', 'ageing potential').\"\n",
    "    )\n",
    "    vinification: Optional[str] = Field(\n",
    "        default=None, description=\"Winemaking process (e.g., 'oak-aged', 'carbonic maceration').\"\n",
    "    )\n",
    "    season: Optional[str] = Field(\n",
    "        default=None, description=\"Season the wine is suited for (e.g., 'summer').\"\n",
    "    )\n",
    "    soil_type: Optional[str] = Field(\n",
    "        default=None, description=\"Soil characteristics (e.g., 'limestone', 'volcanic').\"\n",
    "    )\n",
    "\n",
    "    description: Optional[str] = Field(\n",
    "        default=None, description=\"Flavor notes or sensory descriptions.\"\n",
    "    )\n",
    "    occasion: Optional[str] = Field(\n",
    "        default=None, description=\"Occasion suitability (e.g., 'wedding', 'gift').\"\n",
    "    )\n",
    "\n",
    "    body: Optional[str] = Field(\n",
    "        default=None, description=\"Body type (e.g., 'light', 'full-bodied').\"\n",
    "    )\n",
    "    acidity: Optional[str] = Field(\n",
    "        default=None, description=\"Acidity level (e.g., 'crisp', 'low').\"\n",
    "    )\n",
    "    alcohol: Optional[float] = Field(\n",
    "        default=None, description=\"Alcohol content as a percentage (e.g., 13.5).\"\n",
    "    )\n",
    "    fruitiness: Optional[str] = Field(\n",
    "        default=None, description=\"Level of fruitiness (e.g., 'dry', 'juicy').\"\n",
    "    )\n",
    "    minerality: Optional[str] = Field(\n",
    "        default=None, description=\"Presence of mineral notes (e.g., 'chalky').\"\n",
    "    )\n",
    "    sweetness: Optional[str] = Field(\n",
    "        default=None, description=\"Sweetness level (e.g., 'dry', 'semi-sweet').\"\n",
    "    )\n",
    "    food_pairings: List[FoodPairing] = Field(\n",
    "        default=None,\n",
    "        description=\"List of recommended or matching food pairings.\"\n",
    "    )\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field_name, field in self.model_fields.items():\n",
    "            val = getattr(self, field_name)\n",
    "            if val is not None and val != field.default:\n",
    "                print(f\"{field_name}: {val}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3951ec-46df-4018-8cc7-1be920c9ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are an expert at converting user questions into structured metadata filters \n",
    "to query a database of wine products\n",
    "\n",
    "Your job is to convert a user's question into a JSON object that matches the following schema:\n",
    "\n",
    "{\n",
    "  \"wine_name\": \"Optional[str]\",              // Specific wine name mentioned\n",
    "  \"variant_id\": \"Optional[int]\",             // Specific product variant ID\n",
    "  \"size\": \"Optional[str]\",                   // Bottle size (e.g. \"750ml\", \"1.5L\")\n",
    "  \"volume_unit\": \"Optional[str]\",            // Units for volume (e.g. \"ml\", \"L\")\n",
    "  \"rating\": \"Optional[str]\",                 // Expert or user rating (e.g. \"90+\", \"4.5 stars\")\n",
    "  \"stock\": \"Optional[int]\",                  // Stock availability if specified\n",
    "\n",
    "  \"min_price\": \"Optional[float]\",            // Minimum price filter (inclusive)\n",
    "  \"max_price\": \"Optional[float]\",            // Maximum price filter (inclusive)\n",
    "\n",
    "  \"winemaker\": \"Optional[str]\",              // Name of the winemaker or producer\n",
    "  \"vintage\": \"Optional[int]\",                // Vintage year (e.g. 2015)\n",
    "  \"country\": \"Optional[str]\",                // Country of origin\n",
    "  \"region\": \"Optional[str]\",                 // Region or appellation\n",
    "  \"wine_type\": \"Optional[str]\",              // Type of wine (e.g. red, white, rosÃ©, sparkling)\n",
    "  \"wine_grapes\": \"Optional[str]\",            // Grape variety or blend (e.g. Merlot, Syrah)\n",
    "\n",
    "  \"level_to_drink\": \"Optional[str]\",         // Drinkability status (e.g. \"drink now\", \"ageing potential\")\n",
    "  \"vinification\": \"Optional[str]\",           // Wine-making process (e.g. \"oak-aged\", \"carbonic maceration\")\n",
    "  \"season\": \"Optional[str]\",                 // Season the wine is suited for (e.g. \"summer\", \"winter\")\n",
    "  \"soil_type\": \"Optional[str]\",              // Soil characteristics (e.g. \"limestone\", \"volcanic\")\n",
    "\n",
    "  \"description\": \"Optional[str]\",            // Flavor notes or sensory descriptions\n",
    "  \"occasion\": \"Optional[str]\",               // Occasion suitability (e.g. \"wedding\", \"gift\", \"everyday\")\n",
    "\n",
    "  \"body\": \"Optional[str]\",                   // Body type (e.g. \"light\", \"full-bodied\")\n",
    "  \"acidity\": \"Optional[str]\",                // Acidity level (e.g. \"crisp\", \"low\")\n",
    "  \"alcohol\": \"Optional[float]\",              // Alcohol content (as percentage, e.g. 13.5)\n",
    "  \"fruitiness\": \"Optional[str]\",             // Level of fruitiness (e.g. \"dry\", \"juicy\")\n",
    "  \"minerality\": \"Optional[str]\",             // Presence of mineral notes (e.g. \"chalky\", \"flinty\")\n",
    "  \"sweetness\": \"Optional[str]\",              // Sweetness level (e.g. \"dry\", \"semi-sweet\", \"sweet\")\n",
    "\n",
    "  \"food_pairings\": [                         // List of recommended food matches\n",
    "    {\n",
    "      \"dish_name\": \"Optional[str]\",          // Name of the dish (e.g. \"roast duck\")\n",
    "      \"pairing_type\": \"Optional[str]\",       // Type of pairing (e.g. \"complementary\")\n",
    "      \"course\": \"Optional[str]\",             // Course type (e.g. \"main\", \"dessert\")\n",
    "      \"description\": \"Optional[str]\",        // Description of the pairing rationale\n",
    "      \"suitability\": \"Optional[int]\",        // Suitability score (e.g. 7)\n",
    "      \"acidity\": \"Optional[str]\",            // Matching acidity level (e.g. \"crisp\")\n",
    "      \"regional_pairing\": \"Optional[str]\",   // Regionally traditional pairing (e.g. \"Tuscany\")\n",
    "      \"sweetness\": \"Optional[str]\"           // Matching sweetness level (e.g. \"dry\")\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Only include optional fields if they are explicitly mentioned in the user's query. \n",
    "Return the result as **pure JSON only**, with no code block, no Markdown, and no explanation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab7013-c3cc-40eb-9c1b-ec34eeebe11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only included filterable metadata fields\n",
    "\n",
    "FIELD_MAP = {\n",
    "    \"wine_name\": \"Product Name\",\n",
    "    \"variant_id\": \"VariantID\",\n",
    "    \"size\": \"Size\",\n",
    "    \"volume_unit\": \"Volume Unit\",\n",
    "    \"rating\": \"Expert Ratings\",\n",
    "    \"stock\": \"Stock\",\n",
    "    \"min_price\": \"WS Retail Price\",\n",
    "    \"max_price\": \"WS Retail Price\",\n",
    "    \"winemaker\": \"Winemaker Name\",\n",
    "    \"vintage\": \"Vintage (Year)\",\n",
    "    \"country\": \"Country\",\n",
    "    \"region\": \"Region\",\n",
    "    \"wine_type\": \"Wine Type\",\n",
    "    \"wine_grapes\": \"Wine Grapes\",\n",
    "    \"season\": \"Season\",\n",
    "    \"soil_type\": \"Soil Type\",\n",
    "    \"occasion\": \"Occasion\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01f672-e880-49cd-986f-60930b18919d",
   "metadata": {},
   "source": [
    "**More helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ae98a79-0efc-47bd-a4fb-bf6d776dcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_analyzer(question: str) -> WineMetadata:\n",
    "    \"\"\"\n",
    "    Converts a natural language question into a structured TutorialSearch query\n",
    "    using a DeepSeek LLM backend.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=system),\n",
    "        HumanMessage(content=question)\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    parsed_dict = extract_json_from_llm_output(response.content)\n",
    "    return WineMetadata(**parsed_dict)\n",
    "\n",
    "def filter_wines(data, model_instance, field_map, max_results=20):\n",
    "    \"\"\"\n",
    "    Given metadata filters constructed from user query using LLM,\n",
    "    returns first n wine profiles that match. \n",
    "    \"\"\"\n",
    "    filters = model_instance.model_dump(exclude_none=True)\n",
    "    results = []\n",
    "\n",
    "    for wine in data:\n",
    "        match = True\n",
    "        for key, value in filters.items():\n",
    "            if key in (\"food_pairings\"):\n",
    "                continue\n",
    "                \n",
    "            elif key in (\"min_price\", \"max_price\"):\n",
    "                price_field = field_map[key]\n",
    "                try:\n",
    "                    wine_price = float(wine.get(price_field,0))\n",
    "                except ValueError:\n",
    "                    match = False\n",
    "                    break\n",
    "                if key == \"min_price\" and wine_price < value:\n",
    "                    match = False\n",
    "                    break\n",
    "                if key == \"max_price\" and wine_price > value:\n",
    "                    match = False\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                field = field_map.get(key)\n",
    "                if field not in wine:\n",
    "                    match = False\n",
    "                    break\n",
    "                wine_val = str(wine[field]).lower().strip()\n",
    "                query_val = str(value).lower().strip()\n",
    "                if query_val not in wine_val:\n",
    "                    match = False\n",
    "\n",
    "        if match:\n",
    "            results.append(wine)\n",
    "            if len(results)== max_results:\n",
    "                break\n",
    "\n",
    "    return results\n",
    "\n",
    "def create_taste_profile(parsed_query):\n",
    "    \"\"\"\n",
    "    Enriches food taste profile from user query using LLM.\n",
    "    \"\"\"\n",
    "    data = parsed_query.model_dump(exclude_none=True)\n",
    "\n",
    "    # Check if food_pairing exists and is not empty\n",
    "    food_pairings = data.get(\"food_pairings\")\n",
    "    pairing_descriptions = []\n",
    "    if food_pairings:\n",
    "        # Extract raw attributes\n",
    "        for pairing in food_pairings:\n",
    "            if isinstance(pairing, dict):\n",
    "                entries = [f\"{key}: {value}\" for key, value in pairing.items() if value]\n",
    "                block = \"\\n\".join(entries)\n",
    "                pairing_descriptions.append(block)\n",
    "            else:\n",
    "                try:\n",
    "                    entries = [f\"{key}: {getattr(pairing, key)}\" for key in pairing.__fields__ if getattr(pairing, key)]\n",
    "                    block = \"\\n\".join(entries)\n",
    "                    pairing_descriptions.append(block)\n",
    "                except:\n",
    "                    continue\n",
    "        raw_input = \"\\n\\n---\\n\\n\".join(pairing_descriptions)\n",
    "\n",
    "        # RAG\n",
    "        response = qa_chain.invoke(f\"Create a taste profile based on the following context: {raw_input}\")\n",
    "        return response[\"result\"]\n",
    "    return None               \n",
    "\n",
    "def generate_recommendations(filtered, profile, top_k=5):\n",
    "    \"\"\"\n",
    "    Performs similarity search between embeddings of (a) each of the filtered wines\n",
    "    and (b) enriched taste profile from query, if present otherwise randomly \n",
    "    sample 3 wines (cheapest -> middle -> most expensive)\n",
    "    \"\"\"\n",
    "    if profile:\n",
    "        embedded_wines = []\n",
    "        for wine in filtered:\n",
    "            content = \"\\n\".join(f\"{key}: {value}\" for key, value in wine.items() if value)\n",
    "            wine_embed = embd.embed_query(content)\n",
    "            embedded_wines.append((wine, wine_embed))\n",
    "\n",
    "        profile_embed = embd.embed_query(profile)\n",
    "        scored_embed = [(wine, cosine_similarity(profile_embed, wine_embed)) for wine, wine_embed in embedded_wines]\n",
    "        top_wines = sorted(scored_embed, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        return [wine for wine, _ in top_wines]\n",
    "\n",
    "    else:\n",
    "        sorted_wines = sorted(filtered, key=lambda x: float(x.WS_Retail_Price))\n",
    "        n = len(sorted_wines)\n",
    "        if n == 0:\n",
    "            return []\n",
    "        step = max(1, n // top_k)\n",
    "        sampled = [random.choice(sorted_wines[i:i+step]) for i in range(0, n, step)][:top_k]\n",
    "\n",
    "        return sampled \n",
    "\n",
    "def ask_ai(question, data, field_map):\n",
    "    start_main = time.time()\n",
    "    parsed_query = query_analyzer(question)\n",
    "    filtered = filter_wines(data=data, model_instance=parsed_query, field_map=field_map)\n",
    "    profile = create_taste_profile(parsed_query)\n",
    "    recommendations = generate_recommendations(filtered, profile)\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf8b1294-abe1-41b0-be5a-34fd8cd70ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"with_images_wshk_final_data - enriched_processed_wine_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "json_data = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f5a40-448a-4d61-95f2-fc6d4220ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "\"What wine goes well with spicy Thai green curry with coconut milk?\",\n",
    "\"Recommend a red wine under 300 HKD that pairs well with grilled lamb and comes from Spain\",\n",
    "\"Suggest a celebratory wine that works with oysters and has high acidity.\",\n",
    "\"I'm cooking mushroom risotto and want something medium-bodied and earthy to go with it.\",\n",
    "\"Pair a bold Napa Cabernet Sauvignon with sushi.\",\n",
    "]\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    print(questions[i])  # Correct variable name\n",
    "    recommendation = ask_ai(question=questions[i], data=wine_json, field_map=FIELD_MAP)\n",
    "    if recommendation == None:\n",
    "        print(\"No recommendations found\")\n",
    "        continue\n",
    "\n",
    "    for j in range(5):\n",
    "        try:\n",
    "            print(f\"Wine {j+1}:\", recommendation[j]['Product Name'])\n",
    "        except:\n",
    "            print(\"No more suggested wines\")\n",
    "            continue\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0440e18-e971-4682-9fc8-764e2d77afb3",
   "metadata": {},
   "source": [
    "What wine goes well with spicy Thai green curry with coconut milk?\n",
    "Wine 1: Alain Chavy  Puligny  Montrachet 202\n",
    "Wine 2: Aldeneyck Herenlaak Chardonnay Maseik, Belgium 2020\n",
    "WIne 3: Anne et Jean-Francois Ganevat Cotes du Jure La Barraque Savagnin 2020\n",
    "Wine 4: Armand Heitz Saint Aubin 1er cru murgers dent de chien 2019\n",
    "Wine 5: Billaud Simon Chablis Tete dOr 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "rag-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
